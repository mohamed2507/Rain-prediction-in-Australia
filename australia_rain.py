# -*- coding: utf-8 -*-
"""Australia rain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fnXGfJS84JoAZlRd6dN0H7EMeICPalx9
"""

! pip install -q kaggle

from google.colab import files
files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 777 ~/.kaggle/kaggle.json

! kaggle datasets list

!kaggle datasets download -d jsphyg/weather-dataset-rattle-package

! unzip weather-dataset-rattle-package.zip -d /content/

import pandas as pd

data =pd.read_csv("/content/weatherAUS.csv")

data.head()

data.shape

data.isna().any()

data['MinTemp']=data['MinTemp'].fillna(data['MinTemp'].mean())

for t in data.loc[:,data.isna().any()]:
  if(data[t].dtype=="float64"):
    data[t]=data[t].fillna(data[t].mean())

data.loc[:,data.isna().any()]

data.shape[0]-data.isna().any(axis=1).sum()

data=data[data.isna().any(axis=1)==False]

data.loc[:,data.isna().any()]

data=data.drop(labels="Date",axis=1)

for t in data:
  if(data[t].dtype=="object"):
    print(t)
data=pd.get_dummies(data,columns=["Location","WindGustDir","WindDir9am","WindDir3pm","RainToday"])

data.loc[data["RainTomorrow"]=="No","RainTomorrow"]=0
data.loc[data["RainTomorrow"]=="Yes","RainTomorrow"]=1
data["RainTomorrow"].value_counts()

data.head()

'''
print(data.isna().any().sum())
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
not_scaled_data=data.loc[:,data.columns!="RainTomorrow"]
scaled_data= pd.DataFrame(scaler.fit_transform(not_scaled_data), columns=not_scaled_data.columns)
scaled_data.head()'''

#data.loc[:,data.columns!="RainTomorrow"]=scaled_data

print(data.isna().any().sum())
data=data[data.isna().any(axis=1)==False]
data.isna().any().sum()

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(data.loc[:,data.columns!="RainTomorrow"],data.loc[:,"RainTomorrow"],test_size=0.2,shuffle=True)

X_test.head()

X_train=X_train.to_numpy().astype('float32')
Y_train=Y_train.to_numpy().astype('float32')

from keras.models import Sequential
from keras.layers import Dense
from tensorflow.keras import regularizers

model=Sequential([
               Dense(16,input_shape=(113,),activation="relu"),
               Dense(32,activation="relu"),
               Dense(64,activation="relu"),
               Dense(128,activation="relu"),
               Dense(256,activation="relu"),
               Dense(1,activation="sigmoid"),   
])

model.compile(loss="binary_crossentropy",optimizer="adam",metrics=['accuracy'])

model.fit(X_train,Y_train,epochs=10,batch_size=16)

X_test=X_test.to_numpy().astype('float32')
Y_test=Y_test.to_numpy().astype('float32')

model.evaluate(X_test,Y_test)

prediction=model.predict(X_test)
prediction[prediction>0.5]=1
prediction[prediction<0.5]=0

from sklearn.metrics import confusion_matrix
c=confusion_matrix(Y_test,prediction)

precision =c[0,0]/(c[0,0]+c[0,1])
recall =c[0,0]/(c[0,0]+c[1,0])
f1_score=2*(precision*recall)/(precision+recall)
print('f1_score: '+str(f1_score ))

d=X_test
d['RainTomorrow']=prediction
d.loc[d['RainTomorrow']==1].head()

prediction